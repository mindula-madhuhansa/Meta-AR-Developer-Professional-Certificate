1. What is computer vision?

   - [ ] An app that allows you to use AR on your mobile device.
   - [x] **A form of artificial intelligence that allows systems to derive meaningful information from digital inputs such as videos or images.**
   - [ ] Artificial intelligence that allows computers to “think.”
   - [ ] An environment that is digital but the content is real.
     > Computer vision trains computers to interpret, understand and react to what they’re seeing.

2. What inputs do computer vision models use to create and enhance the AR experience?

   - [ ] Verbal cues
   - [x] **Pixels generated from a camera**
   - [ ] Words and syntax from targeted sites
   - [ ] No inputs are needed for the AR experience
     > AI models are trained to understand the pixels generated by a camera. With this understanding, the computer can know what it’s looking at and provide additional data that is then able to be used in AR applications.

3. AR drives computer vision capabilities.

   - [ ] True
   - [x] **False**
     > It’s actually the other way around. Computer vision drives AR capabilities by using AI models that are trained to understand the pixels generated by a camera. With this understanding, the computer can know what it’s looking at and provide additional data that is then able to be used in AR applications.

4. File size is not important when developing algorithms for computer vision with AR effects.

   - [ ] True
   - [x] **False**
     > Algorithms can be very large in size if not developed correctly. Consumers may have limited bandwidth to download content onto their phones, and the storage on phones is typically more limited than on a desktop.

5. Why is it important to create extremely detailed and distinct images when using computer vision to design AR effects?

   - [ ] Computer vision uses cameras to “see” data and interpret it. There is no need for additional detail.
   - [x] **The computer vision model will only be as good as the data fed into it.**
   - [ ] Computer vision only sees in black and white and will need additional details to colorize and add dimension.
   - [ ] The detail doesn’t matter so much as the size and depth of the image.
     > The computer vision model will only be as good as the data fed into it. Create extremely detailed images that are so distinct, the computer cannot mistake different elements in the image. Any missing information or biases that are inherent to the data sets fed to the training algorithm will affect how the model is trained.

6. What can negatively impact the AR experience for certain categories of users?

   - [ ] OS choices
   - [ ] Certain colors
   - [ ] Bandwidth
   - [x] **Bias**
     > Bias can result in the machine learning model being consistently wrong on certain categories because of less frequency of the examples in the training data. Bias can negatively impact the AR experience for certain categories of users. With this in mind, it's very important that ML models are trained to mitigate bias.

7. What AR software is used to position digital content in a three-dimensional environment?

   - [ ] SLAM
   - [x] **Spatial mapping and anchoring**
   - [ ] SPAM
   - [ ] Object detection
     > Spatial mapping and anchoring is a common AR experience in which AR software works to understand the three dimensional environment and then positions the digital content on that 3D space. The AR system might use machine learning to collect data points.

8. What does computer vision recognize?

   - [x] **Patterns**
   - [ ] Shapes
   - [ ] Figures
   - [ ] Numbers
     > On a basic level, computer vision is recognizing patterns. Vision algorithms need to recognize objects from different perspectives and in different environments.

9. What type of algorithm defines texture, color and opacity?

   - [x] **Shaders**
   - [ ] Spatial mapping
   - [ ] Anchors
   - [ ] Sliders
     > Shader algorithms define what the surface of a 3D model looks like — the texture, the color, the opacity and more.

10. What does SLAM stand for?

    - [ ] Serial localization and mapping
    - [ ] Serial login and mutation
    - [x] **Simultaneous localization and mapping**
    - [ ] Soto localizations and manipulation
      > SLAM, or simultaneous localization and mapping, is a process used by an AR system to estimate its motion. On a very high level, SLAM builds up a map of the environment by tracking 2D points in images.
